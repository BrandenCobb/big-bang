# Define global rules for when pipelines run
workflow:
  rules:
    # Skip pipeline when commit message starts with "wip"
    - if: '$CI_COMMIT_MESSAGE =~ /^wip/'
      when: never
    # Skip pipeline for branches that start with "docs"
    - if: '$CI_COMMIT_BRANCH =~ /^docs/'
      when: never
    - when: always

include:
  - project: 'platform-one/big-bang/pipeline-templates/umbrella-templates'
    file: '/global.gitlab-ci.yml'
    
stages:
  - smoke tests
  - network up
  - cluster up
  - bigbang up
  - test
  - bigbang down
  - cluster down
  - network down
  - release prepare
  - release airgap
  - release upload
  - release variables
  - release

.bigbang:
  image: registry.dsop.io/platform-one/big-bang/pipeline-templates/pipeline-templates/k3d-builder:0.0.1

.deploy_bigbang: &deploy_bigbang
  # TODO - Clean this up
  # Deploy flux and wait for it to be ready
  - kubectl apply -f https://repo1.dsop.io/platform-one/big-bang/apps/sandbox/fluxv2/-/raw/master/flux-system.yaml
  - flux check
  # Deploy BigBang
  - helm upgrade -i bigbang chart -n bigbang --create-namespace --set registryCredentials.username='robot$bigbang' --set registryCredentials.password=${REGISTRY1_PASSWORD} --set addons.argocd.enabled=true --set addons.authservice.enabled=true
  # Apply secrets kustomization pointing to current branch
  - echo "Deploying secrets from branch ${CI_COMMIT_REF_NAME}"
  - cat examples/complete/envs/dev/source-secrets.yaml | sed 's|master|'$CI_COMMIT_REF_NAME'|g' | kubectl apply -f -
  # wait for components to be ready
  - kubectl wait --timeout=15m --for=condition=Ready -n bigbang $(kubectl get hr -n bigbang -o name)
  # Quick check for non iron bank images
  - echo "Showing non ironbank images:"
  # Ignore rancher images since those are from k3d
  - ./airgap/list-images.sh | grep -v "registry1" | grep -v "rancher"

#-----------------------------------------------------------------------------------------------------------------------

#-----------------------------------------------------------------------------------------------------------------------
# Infrastructure: Management Jobs
#

# .pre job for pulling pipeline contents from umbrella-templates project
# TODO: Currently all jobs connected via "needs" must explicitly need this job, should evaluate turning this into a global cache
fetch umbrella templates:
  extends:
    - .fetch
    - .infra create
  stage: .pre

# Abstract for job manually triggering infrastructure builds
.infra fork:
  stage: network up
  needs:
    - fetch umbrella templates
  rules:
    # Skip when branch name starts with "hotfix" or "patch"
    - if: '$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME =~ /^(hotfix|patch)/'
      when: never
    # Only run on merge requests when manually activated
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: false

# Abstract for jobs responsible for creating infrastructure
.infra create:
  rules:
    # Skip when branch name starts with "hotfix" or "patch"
    - if: '$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME =~ /^(hotfix|patch)/'
      when: never
    # Only run on merge requests
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'

# Abstract for jobs responsible for cleaning up infrastructure
.infra cleanup:
  rules:
    # Skip when branch name starts with "hotfix" or "patch"
    - if: '$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME =~ /^(hotfix|patch)/'
      when: never
    # Always run on merge requests
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      allow_failure: true
      when: always
      
#-----------------------------------------------------------------------------------------------------------------------

#-----------------------------------------------------------------------------------------------------------------------
# Infrastructure: Networking
#

aws/network up:
  extends:
    - .infra fork
    - .network up
  environment:
    name: review/aws-${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHORT_SHA}
    auto_stop_in: 1 hour

aws/network down:
  extends:
    - .infra cleanup
    - .network down
  stage: network down
  environment:
    name: review/aws-${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHORT_SHA}
    action: stop

#-----------------------------------------------------------------------------------------------------------------------

#-----------------------------------------------------------------------------------------------------------------------
# Infrastructure: RKE2
#

# Create RKE2 cluster on AWS
aws/rke2/cluster up:
  stage: cluster up
  extends:
    - .infra create
    - .rke2 up
  needs:
    - job: fetch umbrella templates
      artifacts: true
    - job: aws/network up

# Install BigBang on RKE2 cluster on AWS
aws/rke2/bigbang up:
  stage: bigbang up
  extends:
    - .infra create
    - .bigbang
  needs:
    - job: fetch umbrella templates
      artifacts: true
    - job: aws/rke2/cluster up
      artifacts: true
  before_script:
    - mkdir -p ~/.kube
    - cp ${CI_PROJECT_DIR}/rke2.yaml ~/.kube/config
    # Deploy a default storage class for aws
    - kubectl apply -f ${CI_PROJECT_DIR}/umbrella-templates/jobs/rke2/dependencies/k8s-resources/aws/default-ebs-sc.yaml
  script:
    - *deploy_bigbang
  after_script:
    - kubectl get all -A

# Run tests on BigBang on RKE2 cluster on AWS
aws/rke2/bigbang test:
  stage: test
  extends:
    - .infra create
    - .bigbang
  needs:
    - job: fetch umbrella templates
      artifacts: true
    - job: aws/rke2/cluster up
      artifacts: true
    - job: aws/rke2/bigbang up
  script:
    - echo "tests go here"

# Uninstall BigBang on RKE2 cluster on AWS
aws/rke2/bigbang down:
  stage: bigbang down
  extends:
    - .infra cleanup
    - .bigbang
  needs:
    - job: fetch umbrella templates
      artifacts: true
    - job: aws/rke2/cluster up
      artifacts: true
    - job: aws/rke2/bigbang test
  before_script:
    - mkdir -p ~/.kube
    - cp ${CI_PROJECT_DIR}/rke2.yaml ~/.kube/config
  script:
    - helm un -n bigbang bigbang

    # TODO: Smarter wait
    - sleep 180
  after_script:
    - kubectl get all -A

# Destroy RKE2 cluster on AWS
aws/rke2/cluster down:
  stage: cluster down
  extends:
    - .infra cleanup
    - .rke2 down
  needs:
    - job: fetch umbrella templates
      artifacts: true
    - job: aws/rke2/bigbang down
    
#-----------------------------------------------------------------------------------------------------------------------

#-----------------------------------------------------------------------------------------------------------------------
# Smoke Tests
#

clean install:
  stage: smoke tests
  extends:
    - .k3d
  rules:
    # Skip on merge requests (it is ran as part of the non MR pipeline)
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: never
    - when: never
  variables:
    CLUSTER_NAME: "clean-${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHORT_SHA}"
  script:
    - *deploy_bigbang

upgrade:
  stage: smoke tests
  extends:
    - .k3d
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  variables:
    CLUSTER_NAME: "clean-${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHORT_SHA}"
  script:
    - echo "Install Big Bang from ${CI_DEFAULT_BRANCH}"
    - git fetch && git checkout ${CI_DEFAULT_BRANCH}
    - *deploy_bigbang

    - echo "Upgrade Big Bang from ${CI_MERGE_REQUEST_SOURCE_BRANCH_NAME}"
    - git checkout ${CI_MERGE_REQUEST_SOURCE_BRANCH_NAME}
    - *deploy_bigbang

#-----------------------------------------------------------------------------------------------------------------------

#-----------------------------------------------------------------------------------------------------------------------
# Release Logic
#

# vendor repos
release prepare repos:
  stage: release prepare
  # TODO - Change this to registry1
  image: docker.io/python:3
  artifacts:
    paths:
      - airgap/tarballs/repos.tar.gz
  script:
  # vendor umbrella repository
  - ./airgap/vendor_umbrella.sh airgap/repos/umbrella
  # vendor repositories from chart/values.yaml
  - pip install $(./airgap/vendor_repos.py pip)
  - ./airgap/vendor_repos.py vendor chart/values.yaml airgap/repos/packages
  # debug statements
  - ls -lah airgap/repos
  - ls -lah airgap/repos/packages
  # create repos tarball
  - tar -zcvf airgap/tarballs/repos.tar.gz airgap/repos >/dev/null

# generate images
# TODO - we need to bump the gitlab artifact max size / generally tidy up gitlab runners
release prepare images:
  stage: release prepare
  extends:
    - .k3d
  services:
    - docker:dind
  variables:
    DOCKER_HOST: tcp://localhost:2375/
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ""
    CLUSTER_NAME: "clean-${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHORT_SHA}"
  artifacts:
    paths:
      - airgap/lists/images.txt
      # - airgap/tarballs/images.tar.gz
      - airgap/tarballs/images-TEST.tar.gz
  script:
  # wait for initial cluster state
  # TODO - put this in upstream k3d init gitlab ci logic
  - for i in {1..10}; do kubectl wait --for=condition=Ready -n kube-system $(kubectl get po -n kube-system -o name) 2>/dev/null && break || sleep 1; done
  # obtain false images from blank cluster state
  - ./airgap/list-images.sh > airgap/lists/images-false.txt
  - cat airgap/lists/images-false.txt
  # deploy bigbang
  - *deploy_bigbang
  # obtain initial images from full cluster state
  - ./airgap/list-images.sh > airgap/lists/images-initial.txt
  - cat airgap/lists/images-initial.txt
  # obtain true images from both lists
  - grep -v -x -f airgap/lists/images-false.txt airgap/lists/images-initial.txt > airgap/lists/images.txt
  - cat airgap/lists/images.txt
  # TODO - Either git source the final images list in CI, or verify it against the existing list
  # create images tarball
  # TODO - Change this to DOCKER_AUTH_CONFIG (Someone with admin needs to do this)
  - docker login registry1.dsop.io -u 'robot$bigbang' -p ${REGISTRY1_PASSWORD}
  - ./airgap/bundle-images.sh --image-list airgap/lists/images.txt --images airgap/tarballs/images.tar.gz
  # TODO - Test
  - touch airgap/tarballs/images-TEST.tar.gz

# test airgap
release airgap:
  stage: release airgap
  extends:
    - .k3d
  services:
    - docker:dind
  variables:
    DOCKER_HOST: tcp://localhost:2375/
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ""
    CLUSTER_NAME: "clean-${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHORT_SHA}"
  dependencies:
    - release prepare images
  script:
  - ls -lah airgap/tarballs
  - ls -lah airgap/lists
  - echo "Airgap test"
  # # TODO - Find a way to disallow container pulling, but allow cloning of repo1 git repos
  # # disable dns to test airgap
  # - echo "" > /etc/resolv.conf
  # - ping google.com || true
  # - which nslookup || true
  # - nslookup google.com || true
  # # import images tarball into k3d cluster
  # - k3d image import airgap/tarballs/images.tar.gz
  # # deploy bigbang
  # - *deploy_bigbang

release upload:
  stage: release upload
  dependencies:
    - release prepare repos
    - release prepare images
  script:
  # TODO - Upload tarball artifacts here
  - ls -lah airgap/repos
  - ls -lah airgap/tarballs
  - ls -lah airgap/lists
  - echo "Upload"

release variables:
  stage: release variables
  artifacts:
    reports:
      dotenv: variables.env
  script:
  # obtain release tag name
  - echo "TAG=v$(cat chart/Chart.yaml | yq r - version)" >> variables.env
  - cat variables.env

# release git / tag
# https://docs.gitlab.com/ee/ci/yaml/#release
release:
  stage: release
  needs:
    - job: release variables
      artifacts: true
  # release:
  #   name: "$TAG"
  #   description: "Umbrella release $TAG, created via GitLab CI releases"
  #   tag_name: "$TAG"
  #   ref: "$CI_COMMIT_SHA"
  script:
  # Ideas - use gitlab releases because it's really nice
  # Compare master chart version with working chart version to determine if we need to upgrade
  # IE - Dev introduces breaking change + updates working Chart.yaml version to breaking change version in same MR
  # Merge request event happens when MR is merged in, not on all MR pipelines, this way we can update Chart.yaml version
  # -- working Chart.yaml version is compared against master to determine if we need to test upgrades going forward
  # No need to store next versions, breaking change placeholders, or anything else - just plain git "history" comparisons
  # We can use conventional commits, but this wouldn't really leverage them in CI, they would just "be a thing"?
  - echo $TAG
  - exit 1 # TODO - Don't remove this until production
  # rules:
  #   - if: $CI_COMMIT_TAG
  #     when: never                                  # Do not run this job when a tag is created manually
  #   - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH  # Run this job when commits are pushed or merged to the default branch

#-----------------------------------------------------------------------------------------------------------------------